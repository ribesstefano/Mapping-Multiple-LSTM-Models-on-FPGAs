{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Kernel-V\n",
    "\n",
    "This notebook will test an IP written in Vivado HLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import allocate\n",
    "import numpy as np\n",
    "from pynq import DefaultIP\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program FPGA and inspect Overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pynq.pl_server.device.XlnkDevice object at 0xafbe7350>\n"
     ]
    }
   ],
   "source": [
    "overlay = Overlay('overlay/kernel_v.bit')\n",
    "print(overlay.device)\n",
    "overlay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the kernel register map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegisterMap {\n",
       "  CTRL = Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0),\n",
       "  GIER = Register(Enable=0, RESERVED=0),\n",
       "  IP_IER = Register(CHAN0_INT_EN=0, CHAN1_INT_EN=0, RESERVED=0),\n",
       "  IP_ISR = Register(CHAN0_INT_ST=0, CHAN1_INT_ST=0, RESERVED=0),\n",
       "  num_active_inputs = Register(num_active_inputs=0),\n",
       "  output_size = Register(output_size=0),\n",
       "  num_refinements_1 = Register(num_refinements=0),\n",
       "  num_refinements_2 = Register(num_refinements=0)\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = overlay.HlsKernelV_0\n",
    "kernel.register_map\n",
    "# print(\"stream size: \", adder.stream_size)\n",
    "# accel_state = adder.get_state()\n",
    "# print(\"accelerator state: \", accel_state)\n",
    "# dma = overlay.axi_dma_0\n",
    "# dma.register_map.MM2S_DMASR\n",
    "# dma.register_map.S2MM_DMACR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel IP can be automatically bound by first creating our Kernel class. Then, the overlay can be instantiated again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelDriver(DefaultIP):\n",
    "    def __init__(self, description):\n",
    "        super().__init__(description=description)\n",
    "    \n",
    "    bindto = ['xilinx.com:hls:HlsKernelV:1.0']\n",
    "\n",
    "    def start_accel(self):\n",
    "        self.register_map.CTRL.AP_START = 1\n",
    "        self.write(0x0, 1)\n",
    "        self.write(0x0, 1)\n",
    "        while(self.read(0x0) % 2 == 0):\n",
    "            self.write(0x0, 1)\n",
    "            pass # Wait until start, i.e. bit 0, is set.\n",
    "\n",
    "    def set_state(self, state):\n",
    "        # self.register_map.CTRL = state\n",
    "        # return self.register_map.CTRL\n",
    "        self.write(0x0, state)\n",
    "        return self.read(0x0)\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.register_map.CTRL\n",
    "        # return self.read(0x0)\n",
    "\n",
    "    @property\n",
    "    def num_refinements(self):\n",
    "        return (self.register_map.num_refinements_1, self.register_map.num_refinements_2)\n",
    "        # return self.read(0x10)\n",
    "\n",
    "    @num_refinements.setter\n",
    "    def num_refinements(self, R):\n",
    "        self.register_map.num_refinements_1 = R[0]\n",
    "        self.register_map.num_refinements_2 = R[1]\n",
    "        # self.write(0x10, R)\n",
    "\n",
    "    @property\n",
    "    def num_active_inputs(self):\n",
    "        return self.register_map.num_active_inputs\n",
    "        # return self.read(0x10)\n",
    "\n",
    "    @num_active_inputs.setter\n",
    "    def num_active_inputs(self, N):\n",
    "        self.register_map.num_active_inputs = N\n",
    "        # self.write(0x10, R)\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.register_map.output_size\n",
    "        # return self.read(0x10)\n",
    "\n",
    "    @output_size.setter\n",
    "    def output_size(self, H):\n",
    "        self.register_map.output_size = H\n",
    "        # self.write(0x10, R)\n",
    "\n",
    "overlay = Overlay(\"overlay/kernel_v.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_v = overlay.HlsKernelV_0\n",
    "kernel_v.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_v.read(0x10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the class is working, we setup the `num_refinements` using the setter method. We then read its corresponding register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Register(num_refinements=0), Register(num_refinements=0))\n",
      "(Register(num_refinements=1), Register(num_refinements=1))\n"
     ]
    }
   ],
   "source": [
    "print(kernel_v.num_refinements)\n",
    "kernel_v.num_refinements = (1, 1)\n",
    "print(kernel_v.num_refinements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x4\n",
      "0x4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(kernel_v.get_state())\n",
    "# kernel_u.start_accel()\n",
    "print(kernel_v.get_state())\n",
    "kernel_v.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x0\n",
      "0x2\n"
     ]
    }
   ],
   "source": [
    "print(kernel_v.num_active_inputs)\n",
    "kernel_v.num_active_inputs = 2\n",
    "print(kernel_v.num_active_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Allocation and Run\n",
    "\n",
    "The data structures must be contiguosly allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffers setup completed.\n",
      "xus_buffer.shape: (16, 1, 4) - Bytes: 128\n",
      "v_buffer.shape: (16, 2, 4, 4) - Bytes: 1024\n",
      "y_buffer.shape: (2, 1, 4, 4) - Bytes: 64\n"
     ]
    }
   ],
   "source": [
    "# The following parameters are fixed in hardware and cannot be changed:\n",
    "# - The maximum output size H\n",
    "# - The number of gates G\n",
    "# - The tile size Tv\n",
    "H = 128\n",
    "G = 4\n",
    "Tv = 4\n",
    "data_t = np.int16\n",
    "# The following parameters are customizeable in hardware and can be changed:\n",
    "# - The number of refinements R\n",
    "# - The output_size <= H\n",
    "# - The number of active_inputs <= N\n",
    "R = 16\n",
    "N = 1\n",
    "output_size = 8 % 128\n",
    "# NOTE: Working with (R, N, out) == (16, 2, 8) \n",
    "\n",
    "xus_buffer = pynq.allocate(shape=(R, N, G), dtype=data_t)\n",
    "v_buffer = pynq.allocate(shape=(R, output_size // Tv, G, Tv), dtype=data_t)\n",
    "y_buffer = pynq.allocate(shape=(output_size // Tv, N, Tv, G), dtype=data_t)\n",
    "\n",
    "# for i in range(N):\n",
    "#     for j in range(I):\n",
    "#         # for ii in range(R):\n",
    "#         x_buffer[i, j] = data_t(np.random.uniform(low=-2**15, high=2**15))\n",
    "\n",
    "# for i in range(R):\n",
    "#     for j in range(I // Tu):\n",
    "#         for k in range(G):\n",
    "#             for ii in range(Tu):\n",
    "#                 u_buffer[i, j, k, ii] = data_t(np.random.uniform(low=-2**15, high=2**15))\n",
    "\n",
    "# for i in range(R):\n",
    "#     for j in range(G):\n",
    "#         for k in range(N):\n",
    "#             xu_buffer[i, j, k] = 0\n",
    "\n",
    "print('Buffers setup completed.')\n",
    "print(f'xus_buffer.shape: {xus_buffer.shape} - Bytes: {xus_buffer.nbytes}')\n",
    "print(f'v_buffer.shape: {v_buffer.shape} - Bytes: {v_buffer.nbytes}')\n",
    "print(f'y_buffer.shape: {y_buffer.shape} - Bytes: {y_buffer.nbytes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the kernel and then send the data through the DMAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x4\n",
      "0x1\n",
      "Starting transfer:\n",
      "Wait xus...DONE.\n",
      "Wait v...DONE.\n",
      "Wait y...DONE.\n",
      "\n",
      "y_buffer.shape: (2, 1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "kernel_v.num_refinements = (R, R)\n",
    "kernel_v.output_size = output_size\n",
    "kernel_v.num_active_inputs = N\n",
    "print(kernel_v.get_state())\n",
    "kernel_v.start_accel()\n",
    "print(kernel_v.get_state())\n",
    "\n",
    "# Transfer\n",
    "print('Starting transfer:')\n",
    "overlay.xus_dma.sendchannel.transfer(xus_buffer)\n",
    "overlay.v_dma.sendchannel.transfer(v_buffer)\n",
    "overlay.y_dma.recvchannel.transfer(y_buffer)\n",
    "# Then wait\n",
    "print('Wait xus...', end='')\n",
    "overlay.xus_dma.sendchannel.wait()\n",
    "print('DONE.\\nWait v...', end='')\n",
    "overlay.v_dma.sendchannel.wait()\n",
    "print('DONE.\\nWait y...', end='')\n",
    "overlay.y_dma.recvchannel.wait()\n",
    "print('DONE.\\n')\n",
    "\n",
    "print(f'y_buffer.shape: {y_buffer.shape}')\n",
    "# print(f'xu_buffer: {xu_buffer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel(R, x_buffer, u_buffer, xu_buffer):\n",
    "    kernel_u.num_refinements = R\n",
    "    kernel_u.start_accel()\n",
    "    # Transfer\n",
    "    overlay.x_dma.sendchannel.transfer(x_buffer)\n",
    "    overlay.u_dma.sendchannel.transfer(u_buffer)\n",
    "    overlay.xu_dma.recvchannel.transfer(xu_buffer)\n",
    "    # Then wait\n",
    "    overlay.x_dma.sendchannel.wait()\n",
    "    overlay.u_dma.sendchannel.wait()\n",
    "    overlay.xu_dma.recvchannel.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 80.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit run_kernel(R, x_buffer, u_buffer, xu_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Correctness\n",
    "\n",
    "We first find the proper reshape mechanisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36593539 -1.03844877  0.82985754 -0.82067175] [ 0.36593539 -1.03844877  0.82985754 -0.82067175]\n",
      "0.0\n",
      "[-0.07974188  0.01109454 -0.18120697  0.73842526] [-0.07974188  0.01109454 -0.18120697  0.73842526]\n",
      "0.0\n",
      "10 loops, best of 3: 24.1 ms per loop\n",
      "(128, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Reshape: (R, I, G) => (R, I // Tu, G, Tu)\n",
    "# =============================================================================\n",
    "u = np.random.randn(R, I, G)\n",
    "u_tmp = u.copy()\n",
    "u_tmp = np.transpose(u_tmp.reshape(R, I // Tu, Tu, G), (0, 1, 3, 2))\n",
    "print(u[0, 0:4, 0], u_tmp[0, 0, 0, 0:4])\n",
    "print(u[0, 3, 0] - u_tmp[0, 0, 0, 3])\n",
    "\n",
    "# =============================================================================\n",
    "# Reshape: (R, I // Tu, G, Tu) => (I, G, R)\n",
    "# =============================================================================\n",
    "u = np.random.randn(R, I // Tu, G, Tu)\n",
    "u_tmp = u.copy()\n",
    "u_tmp = np.transpose(u_tmp, (1, 3, 2, 0)).reshape(I, G, R)\n",
    "print(u[0, 0, 0, 0:4], u_tmp[0:4, 0, 0])\n",
    "print(u[0, 0, 0, 3] - u_tmp[3, 0, 0])\n",
    "\n",
    "x = np.random.randn(N, I)\n",
    "u = np.random.randn(I, G, R)\n",
    "x = (x * 2).astype(np.int16)\n",
    "u = (u * 2).astype(np.int16)\n",
    "\n",
    "%timeit xu = np.transpose(np.tensordot(x, u, axes=1), (2, 1, 0))\n",
    "print(xu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the Numpy computation against the FPGA result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 105 ms per loop\n",
      "\n",
      "All equal: True\n",
      "gold[0]:  [[  8822 -32153]\n",
      " [-17540   6635]\n",
      " [  6489   5700]\n",
      " [ 11839  25184]]\n",
      "fpga[0]:  [[  8822 -32153]\n",
      " [-17540   6635]\n",
      " [  6489   5700]\n",
      " [ 11839  25184]]\n"
     ]
    }
   ],
   "source": [
    "u_tmp = np.transpose(u_buffer, (1, 3, 2, 0)).reshape(I, G, R)\n",
    "%timeit xu_gold = np.transpose(np.tensordot(x_buffer, u_tmp, axes=1), (2, 1, 0))\n",
    "print('\\nAll equal:', np.allclose(xu_buffer, xu_gold))\n",
    "print('gold[0]: ', xu_gold[0])\n",
    "print('fpga[0]: ', xu_buffer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
