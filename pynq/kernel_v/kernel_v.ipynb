{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Kernel-U\n",
    "\n",
    "This notebook will test an IP written in Vivado HLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import allocate\n",
    "import numpy as np\n",
    "from pynq import DefaultIP\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program FPGA and inspect Overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay(\"overlay/kernel_u.bit\")\n",
    "overlay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the kernel register map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegisterMap {\n",
       "  CTRL = Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0),\n",
       "  GIER = Register(Enable=0, RESERVED=0),\n",
       "  IP_IER = Register(CHAN0_INT_EN=0, CHAN1_INT_EN=0, RESERVED=0),\n",
       "  IP_ISR = Register(CHAN0_INT_ST=0, CHAN1_INT_ST=0, RESERVED=0),\n",
       "  num_refinements = Register(num_refinements=0)\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = overlay.HlsAxisKernelU_0\n",
    "kernel.register_map\n",
    "# print(\"stream size: \", adder.stream_size)\n",
    "# accel_state = adder.get_state()\n",
    "# print(\"accelerator state: \", accel_state)\n",
    "# dma = overlay.axi_dma_0\n",
    "# dma.register_map.MM2S_DMASR\n",
    "# dma.register_map.S2MM_DMACR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel IP can be automatically bound by first creating our Kernel class. Then, the overlay can be instantiated again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelDriver(DefaultIP):\n",
    "    def __init__(self, description):\n",
    "        super().__init__(description=description)\n",
    "    \n",
    "    bindto = ['xilinx.com:hls:HlsAxisKernelU:1.0']\n",
    "\n",
    "    def start_accel(self):\n",
    "        self.register_map.CTRL.AP_START = 1\n",
    "        self.write(0x0, 1)\n",
    "        self.write(0x0, 1)\n",
    "        while(self.read(0x0) % 2 == 0):\n",
    "            self.write(0x0, 1)\n",
    "            pass # Wait until start, i.e. bit 0, is set.\n",
    "\n",
    "    def set_state(self, state):\n",
    "        # self.register_map.CTRL = state\n",
    "        # return self.register_map.CTRL\n",
    "        self.write(0x0, state)\n",
    "        return self.read(0x0)\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.register_map.CTRL\n",
    "        # return self.read(0x0)\n",
    "\n",
    "    @property\n",
    "    def num_refinements(self):\n",
    "        return self.register_map.num_refinements\n",
    "        # return self.read(0x10)\n",
    "\n",
    "    @num_refinements.setter\n",
    "    def num_refinements(self, R):\n",
    "        # self.register_map.num_refinements = R\n",
    "        self.write(0x10, R)\n",
    "\n",
    "overlay = Overlay(\"overlay/kernel_u.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_u = overlay.HlsAxisKernelU_0\n",
    "kernel_u.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_u.read(0x10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the class is working, we setup the `num_refinements` using the setter method. We then read its corresponding register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_u.num_refinements = 1\n",
    "kernel_u.read(0x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x4\n",
      "0x4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Register(AP_START=0, AP_DONE=0, AP_IDLE=1, AP_READY=0, RESERVED_1=0, AUTO_RESTART=0, RESERVED_2=0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(kernel_u.get_state())\n",
    "# kernel_u.start_accel()\n",
    "print(kernel_u.get_state())\n",
    "kernel_u.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Allocation and Run\n",
    "\n",
    "The data structures must be contiguosly allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffers setup completed.\n",
      "x_buffer.shape: (2, 512) - Bytes: 2048\n",
      "u_buffer.shape: (128, 128, 4, 4) - Bytes: 524288\n",
      "xu_buffer.shape: (128, 4, 2) - Bytes: 2048\n"
     ]
    }
   ],
   "source": [
    "# The following parameters are fixed in hardware and cannot be changed:\n",
    "# - The number of inputs N\n",
    "# - The input size I\n",
    "# - The number of gates G\n",
    "# - The tile size Tu\n",
    "I = 512\n",
    "G = 4\n",
    "N = 2\n",
    "Tu = 4\n",
    "data_t = np.int16\n",
    "# The number of refinements R can instead be adjusted.\n",
    "R = 128\n",
    "\n",
    "x_buffer = pynq.allocate(shape=(N, I,), dtype=data_t)\n",
    "u_buffer = pynq.allocate(shape=(R, I // Tu, G, Tu), dtype=data_t)\n",
    "xu_buffer = pynq.allocate(shape=(R, G, N,), dtype=data_t)\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(I):\n",
    "        # for ii in range(R):\n",
    "        x_buffer[i, j] = data_t(np.random.uniform(low=-2**15, high=2**15))\n",
    "\n",
    "for i in range(R):\n",
    "    for j in range(I // Tu):\n",
    "        for k in range(G):\n",
    "            for ii in range(Tu):\n",
    "                u_buffer[i, j, k, ii] = data_t(np.random.uniform(low=-2**15, high=2**15))\n",
    "\n",
    "for i in range(R):\n",
    "    for j in range(G):\n",
    "        for k in range(N):\n",
    "            xu_buffer[i, j, k] = 0\n",
    "\n",
    "print('Buffers setup completed.')\n",
    "print(f'x_buffer.shape: {x_buffer.shape} - Bytes: {x_buffer.nbytes}')\n",
    "print(f'u_buffer.shape: {u_buffer.shape} - Bytes: {u_buffer.nbytes}')\n",
    "print(f'xu_buffer.shape: {xu_buffer.shape} - Bytes: {xu_buffer.nbytes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the kernel and then send the data through the DMAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x4\n",
      "0x1\n",
      "Starting transfer:\n",
      "Wait x...DONE.\n",
      "Wait u...DONE.\n",
      "Wait xu...DONE.\n",
      "\n",
      "xu_buffer.shape: (128, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "kernel_u.num_refinements = R\n",
    "print(kernel_u.get_state())\n",
    "kernel_u.start_accel()\n",
    "print(kernel_u.get_state())\n",
    "\n",
    "# Transfer\n",
    "print('Starting transfer:')\n",
    "overlay.x_dma.sendchannel.transfer(x_buffer)\n",
    "overlay.u_dma.sendchannel.transfer(u_buffer)\n",
    "overlay.xu_dma.recvchannel.transfer(xu_buffer)\n",
    "# Then wait\n",
    "print('Wait x...', end='')\n",
    "overlay.x_dma.sendchannel.wait()\n",
    "print('DONE.\\nWait u...', end='')\n",
    "overlay.u_dma.sendchannel.wait()\n",
    "print('DONE.\\nWait xu...', end='')\n",
    "overlay.xu_dma.recvchannel.wait()\n",
    "print('DONE.\\n')\n",
    "\n",
    "print(f'xu_buffer.shape: {xu_buffer.shape}')\n",
    "# print(f'xu_buffer: {xu_buffer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel(R, x_buffer, u_buffer, xu_buffer):\n",
    "    kernel_u.num_refinements = R\n",
    "    kernel_u.start_accel()\n",
    "    # Transfer\n",
    "    overlay.x_dma.sendchannel.transfer(x_buffer)\n",
    "    overlay.u_dma.sendchannel.transfer(u_buffer)\n",
    "    overlay.xu_dma.recvchannel.transfer(xu_buffer)\n",
    "    # Then wait\n",
    "    overlay.x_dma.sendchannel.wait()\n",
    "    overlay.u_dma.sendchannel.wait()\n",
    "    overlay.xu_dma.recvchannel.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 80.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit run_kernel(R, x_buffer, u_buffer, xu_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Correctness\n",
    "\n",
    "We first find the proper reshape mechanisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36593539 -1.03844877  0.82985754 -0.82067175] [ 0.36593539 -1.03844877  0.82985754 -0.82067175]\n",
      "0.0\n",
      "[-0.07974188  0.01109454 -0.18120697  0.73842526] [-0.07974188  0.01109454 -0.18120697  0.73842526]\n",
      "0.0\n",
      "10 loops, best of 3: 24.1 ms per loop\n",
      "(128, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Reshape: (R, I, G) => (R, I // Tu, G, Tu)\n",
    "# =============================================================================\n",
    "u = np.random.randn(R, I, G)\n",
    "u_tmp = u.copy()\n",
    "u_tmp = np.transpose(u_tmp.reshape(R, I // Tu, Tu, G), (0, 1, 3, 2))\n",
    "print(u[0, 0:4, 0], u_tmp[0, 0, 0, 0:4])\n",
    "print(u[0, 3, 0] - u_tmp[0, 0, 0, 3])\n",
    "\n",
    "# =============================================================================\n",
    "# Reshape: (R, I // Tu, G, Tu) => (I, G, R)\n",
    "# =============================================================================\n",
    "u = np.random.randn(R, I // Tu, G, Tu)\n",
    "u_tmp = u.copy()\n",
    "u_tmp = np.transpose(u_tmp, (1, 3, 2, 0)).reshape(I, G, R)\n",
    "print(u[0, 0, 0, 0:4], u_tmp[0:4, 0, 0])\n",
    "print(u[0, 0, 0, 3] - u_tmp[3, 0, 0])\n",
    "\n",
    "x = np.random.randn(N, I)\n",
    "u = np.random.randn(I, G, R)\n",
    "x = (x * 2).astype(np.int16)\n",
    "u = (u * 2).astype(np.int16)\n",
    "\n",
    "%timeit xu = np.transpose(np.tensordot(x, u, axes=1), (2, 1, 0))\n",
    "print(xu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the Numpy computation against the FPGA result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 105 ms per loop\n",
      "\n",
      "All equal: True\n",
      "gold[0]:  [[  8822 -32153]\n",
      " [-17540   6635]\n",
      " [  6489   5700]\n",
      " [ 11839  25184]]\n",
      "fpga[0]:  [[  8822 -32153]\n",
      " [-17540   6635]\n",
      " [  6489   5700]\n",
      " [ 11839  25184]]\n"
     ]
    }
   ],
   "source": [
    "u_tmp = np.transpose(u_buffer, (1, 3, 2, 0)).reshape(I, G, R)\n",
    "%timeit xu_gold = np.transpose(np.tensordot(x_buffer, u_tmp, axes=1), (2, 1, 0))\n",
    "print('\\nAll equal:', np.allclose(xu_buffer, xu_gold))\n",
    "print('gold[0]: ', xu_gold[0])\n",
    "print('fpga[0]: ', xu_buffer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
